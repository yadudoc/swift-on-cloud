Running Swift with dynamic cloud provisioning
=============================================

1. Sign up online with a cloud provider [Amazon Web Services | Google Compute Engine]
2. Setup local machine with packages.
3. Configure and run!

Miscellaneous topics :
* SSDs on cloud instances
* Boot scripts for workers

Sign up online
^^^^^^^^^^^^^^

Sign up for Amazon Web Services (AWS) and create an IAM user by following instructions
from http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/get-set-up-for-amazon-ec2.html[Amazon's Setup Documentation].
From the documentation you would only need to do the following two steps:

1. http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/get-set-up-for-amazon-ec2.html#sign-up-for-aws[Sign up for AWS]

2. http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/get-set-up-for-amazon-ec2.html#create-an-iam-user[Create and IAM User]

NOTE: To create access keys, you must have permissions to perform the required
IAM actions. For more information, see http://docs.aws.amazon.com/IAM/latest/UserGuide/ManagingCredentials.html[Managing Credentials using IAM].

NOTE: For this tutorial, use the AWS zone US West Oregon.

If you already have an account, here's the steps to get you IAM access keys:
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

1. Go to the IAM console.

2. From the navigation menu, click Users.

3. Select your IAM user name, or create a new one.

4. Click User Actions, and then click Manage Access Keys.

5. Click Create Access Key.

6. Click Download Credentials, and store the keys (a .csv file) in a secure location.

NOTE: Your secret key will no longer be available through the AWS Management Console;
you will have the only copy. Keep it confidential in order to protect your account.

NOTE: Your keys will look something like this: +
Access key ID example    : AKIAIOSFODNN7*EXAMPLE* +
Secret access key example: wJalrXUtnFEMI/K7MDENG/bPxRfiCY*EXAMPLEKEY* +

Setup local-machine
^^^^^^^^^^^^^^^^^^^

To run swift with dynamic provisioning of cloud resources the following are pre-requisites:
* Oracle java ( jdk1.7 preferred )
* Ant (1.9 preferred)
* Python 2.7
* apache-libcloud library

To install Swift-trunk follow steps below:

[source,bash]
-----
git clone https://github.com/swift-lang/swift-k.git
cd swift-k
ant redist
export PATH=$PWD/dist/swift-svn/bin:$PATH
-----

NOTE: Add the path swift-k/dist/swift-svn/bin to the PATH environment variable and export
from either .bashrc or .bash_profile, to ensure that swift is available from your PATH.

Install python and libcloud library. The following are steps for *debian* based
linux distributions such as *Ubuntu*. Once pip is installed, use pip to install apache-libcloud.
[source,bash]
-----
sudo apt-get install python python-pip
sudo pip install apache-libcloud

-----

For *OSX*, do the following:
[source,bash]
-----
port install py-libcloud
-----

Get the cloud-tutorials repository from git
[source,bash]
-----
git clone https://github.com/yadudoc/cloud-tutorials.git
cd cloud-tutorials/ec2
-----

Configure your swift.conf
^^^^^^^^^^^^^^^^^^^^^^^^^

This section is specific to aspects of confiuration parameters for cloud providers. For a more general

Define the jobManager to the cloud provider that you choose :
jobManager : local:<ec2-clouds|gce-cloud>

The configuration options specific to the cloud provider is set under jobOptions.

Here are the options supported by ec2-cloud :

ec2CredentialsFile : Absolute path to a csv file that contains the User name, Access Key Id, and Access Key to the AWS resources.
ec2KeypairName     : Name of the key pair that you wish to use. If you do not have one, provide a name for the key.
ec2KeypairFile     : Absolute path to a .pem file that can be downloaded from the AWS website. If you do not have one, provide
                     the absolute path to where you'd like to keep the swift-generated .pem file.
ec2SecurityGroup   : Provide the security group if you have one, otherwise leave the defaults on swift_security_group1
ec2WorkerImage     : Provide the AMI id of the image you would like to use. Please see notes about AMI's below.
ec2WorkerType      : Set the instance type you require to be provisioned. Eg c3.large, t2.micro
ec2CloudInit       : Full path to a bash script which would be executed along with the cloud-init scripts at boot time of the worker-instance.


Here are the options supported by gce-cloud :

gceSecurityGroup   : swift_security_group1
gceProjectId       :     mystic-pagoda-551
gceWorkerImage     :   "gs://swift-worker/8cdfa8723966ca128d02ac148c67cf46fcd65cd1.image.tar.gz"
gceKeypairFile     :   /home/yadu/.ssh/GCE_priv_key.pem
gceEmailAccount    :  "791876389344-sot5mq0jc6j5hclbsmaguq6crh93mlj4@developer.gserviceaccount.com"
gceZone            :  Select the gce zone to use, eg.  us-central1-a
gceWorkerType      :  Select worker instance type, eg. f1-micro

Here is a sample configuration file :

sites: [aws]
site.aws {
    execution {
        type:"coaster"
        URL: "127.0.0.1"
        jobManager: "local:ec2-cloud"
        options {
            maxJobs: 10
            tasksPerNode: 2
            workerLoggingLevel: TRACE
            workerLoggingDirectory: /tmp
            highOverallocation: 100
            lowOverallocation: 100
            jobOptions {
                # Absolute paths necessary for credentials file
                ec2CredentialsFile: ${env.HOME}/.ssh/swift-grant-credentials.csv
                ec2SecurityGroup:   swift_security_group1
                ec2KeypairName:     swift-test-pair
                # Absolute paths necessary for keypair file
                ec2KeypairFile:     ${env.HOME}/.ssh/swift-test-pair.pem
                ec2WorkerImage:     ami-23700813
                ec2WorkerType:      t1.micro
            }
        }
    }

    initialParallelTasks: 20
    maxParallelTasks: 20
    filesystem.type: swift
    workDirectory: /tmp/swift-trunk-test
    staging: "local"
    app.ALL {executable: "*"}
}
lazyErrors: false


SSD Disks on worker-instances
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Several EC2 instance especially the C3, M3 series come with SSD disks. The workers
are configured to format these disks to ext4 and combine the first two SSD disks
(/dev/xvdb and /dev/xvdc) as striped disks and mount them on /scratch.


Configuring the worker-instance at boot time
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

There's a provision in the worker, to execute scripts from the user at boot-time.
For example you could mount an S3 bucket if you provide the s3 bucket keys and the
mount command as a script to the WORKER_INIT_SCRIPT config parameter.

Assuming that you are using machines with disks, the worker init scripts will mount
them all on /scratch.

The following script sets up the passwd-s3fs file and mounts the s3 bucket on /s3

File  : mounts3fs.sh
[source, bash]
------
echo "AKIAJLBNUBP6D4U52CXQ:FFsNvJ+Dftor46B++++*THIS_IS_ONLY_AN_EXAMPLE*" > /etc/passwd-s3fs; chmod 600 /etc/passwd-s3fs
mkdir /s3; chmod 777 /s3;
s3fs -o allow_other,gid=2300 swift-s3-test /s3 -ouse_cache=/scratch,parallel_count=25
------

Set WORKER_INIT_SCRIPT=/path/to/mounts3fs.sh in cloud-tutorials/ec2/configs before
launching workers.

NOTE: You will have to do this manually on the headnode.




Note: To create your own customised images, you can connect to the swift instances (headnodes/workers) and
modify them. Once done you can create your own images. Documentation on Amazon Machine Images is available
http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html[here]
